{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Imports ######\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes XML tags from the data\n",
    "def clean_data(data):\n",
    "    try:\n",
    "        tags = ET.fromstring(str(data))\n",
    "        return ET.tostring(tags, method='text').decode(\"utf-8\").replace('\\'', '').replace('\\ ', '').replace('\\\"','')\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "# Finds all different places and removes the XML tags from them\n",
    "def clean_places(places):\n",
    "    placelist = []\n",
    "    for i in places:\n",
    "        tags = ET.fromstring(str(i))\n",
    "        placelist.append(ET.tostring(tags, method='text').decode(\"utf-8\"))\n",
    "        \n",
    "    return placelist\n",
    "\n",
    "# Removes title, place and the XML tags from the text\n",
    "def clean_text(text):\n",
    "    for tag in text.findAll():\n",
    "        tag.replaceWith('')\n",
    "    \n",
    "    text = text.text.replace('\\n',' ').replace('\\\"', '').replace('\\'', '').replace('\\ ','')\n",
    "    \n",
    "    return re.sub('[\\x7f]', '', text)\n",
    "\n",
    "def clean_year(data):\n",
    "    year = re.search('[0-9]+-[A-Z]+', str(data)).group(0)\n",
    "    return str(year)\n",
    "\n",
    "# Creates dictionary with all documents in the Reuters database, assigns doc_ID to all documents. \n",
    "def load_data():\n",
    "    data_dict = {}\n",
    "    data_id = 0\n",
    "    \n",
    "    with open('reuters.json', 'w') as f:\n",
    "        for i in range(22):\n",
    "            if i < 10:\n",
    "                data1 = open('reuters_data/reut2-00'+ str(i) +'.sgm')\n",
    "            else:\n",
    "                data1 = open('reuters_data/reut2-0'+ str(i) +'.sgm')\n",
    "            soup = BeautifulSoup(data1,'lxml')\n",
    "            items = soup.findAll('reuters')\n",
    "\n",
    "            for doc in items:\n",
    "                ID =     {'index':{'_id':str(data_id)}}\n",
    "                data =   {'date':clean_year(doc.date),\n",
    "                          'topic':clean_data(doc.topics), \n",
    "                          'place':clean_places(doc.places.findAll('d')), \n",
    "                          'people':clean_data(doc.people), \n",
    "                          'orgs':clean_data(doc.orgs), \n",
    "                          'exchanges':clean_data(doc.exchanges), \n",
    "                          'companies':clean_data(doc.companies), \n",
    "                          'title':clean_data(doc.title), \n",
    "                          'text':clean_text(doc.findAll('text')[0]) \n",
    "                          }\n",
    "                \n",
    "                json.dump(ID, f)\n",
    "                f.write('\\n')\n",
    "                json.dump(data, f)\n",
    "                f.write('\\n')\n",
    "\n",
    "                print('Indexing document', data_id + 1, 'of 21578', end='\\r')\n",
    "                data_id += 1\n",
    "        \n",
    "    return 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing document 21578 of 21578 21578 406 of 21578of 21578662 of 21578 808 of 21578 of 215781295 of 21578 1426 of 215781687 of 215781819 of 21578 1958 of 21578 2155 of 21578 2294 of 21578 2831 of 21578 2981 of 21578 3142 of 215783290 of 21578 3575 of 21578 3701 of 215783829 of 21578 3968 of 21578 4305 of 21578 4841 of 21578 4979 of 21578 5141 of 21578 5276 of 21578 5404 of 21578of 21578 5794 of 21578 6115 of 21578 6193 of 21578 6313 of 21578 6452 of 21578 6830 of 21578 6973 of 21578 7303 of 21578 7435 of 215787566 of 21578 7822 of 21578 7962 of 21578 8286 of 21578 8419 of 21578 8669 of 21578of 21578 of 21578 9536 of 21578 9815 of 2157810145 of 21578 10639 of 21578 10880 of 21578 11264 of 21578 11546 of 21578 11670 of 21578of 21578 of 2157812269 of 21578of 21578 13000 of 21578 13134 of 21578 13277 of 21578 13562 of 21578 13703 of 2157814164 of 21578 14315 of 21578 14885 of 21578 15372 of 21578of 21578 of 21578 15715 of 21578 15834 of 21578 16095 of 21578 16232 of 21578 16352 of 21578 16477 of 2157816741 of 21578 17139 of 21578of 21578 17998 of 21578 18077 of 21578 18211 of 21578 18572 of 21578 18690 of 21578 of 21578 18960 of 2157819138 of 21578 19264 of 21578 19374 of 21578 19485 of 21578 19872 of 21578 20100 of 21578 20205 of 21578 20276 of 21578 20554 of 21578 21095 of 21578 21535 of 21578\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
