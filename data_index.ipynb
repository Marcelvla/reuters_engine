{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Imports ######\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 7999 of 800045 of 8000 491 of 8000 of 8000 793 of 8000of 80001150 of 8000 1294 of 8000 1559 of 8000 1685 of 8000 1808 of 8000 2126 of 8000 2253 of 8000 2363 of 80002470 of 8000 2594 of 8000 2712 of 8000 2823 of 8000 2941 of 8000 of 8000 3259 of 8000 3591 of 8000 3705 of 8000 3825 of 8000 of 8000 4112 of 80004234 of 8000 4350 of 8000of 8000 4572 of 8000 4694 of 8000 4998 of 8000 5148 of 8000 5243 of 8000 5352 of 8000 5461 of 8000 5552 of 8000 5754 of 8000 5880 of 8000 6137 of 8000 6246 of 8000 6380 of 8000 6481 of 8000 6668 of 8000 6758 of 8000 6849 of 8000 6942 of 8000 7088 of 8000 7158 of 8000 7409 of 8000 7469 of 8000 7550 of 8000 of 8000 7712 of 8000 7765 of 8000 7839 of 8000\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removes XML tags from the data\n",
    "def clean_data(data):\n",
    "    try:\n",
    "        tags = ET.fromstring(str(data))\n",
    "        return ET.tostring(tags, method='text').decode(\"utf-8\")\n",
    "    except:\n",
    "        return data\n",
    "\n",
    "# Finds all different places and removes the XML tags from them\n",
    "def clean_places(places):\n",
    "    placelist = []\n",
    "    for i in places:\n",
    "        tags = ET.fromstring(str(i))\n",
    "        placelist.append(ET.tostring(tags, method='text').decode(\"utf-8\"))\n",
    "        \n",
    "    return placelist\n",
    "\n",
    "# Removes title, place and the XML tags from the text\n",
    "def clean_text(text):\n",
    "    for tag in text.findAll():\n",
    "        tag.replaceWith('')\n",
    "\n",
    "    return text.text.replace('\\n','')\n",
    "\n",
    "# Creates dictionary with all documents in the Reuters database, assigns doc_ID to all documents. \n",
    "def load_data():\n",
    "    data_dict = {}\n",
    "    data_id = 0\n",
    "    data_str = ''\n",
    "    for i in range(8):\n",
    "        data1 = open('reuters_data/reut2-00'+ str(i) +'.sgm')\n",
    "        soup = BeautifulSoup(data1,'lxml')\n",
    "        items = soup.findAll('reuters')\n",
    "        \n",
    "        for doc in items:\n",
    "            ID =     str({'docID':data_id})\n",
    "            data =   str({'date':clean_data(doc.date),\n",
    "                          'topic':clean_data(doc.topics), \n",
    "                          'place':clean_places(doc.places.findAll('d')), \n",
    "                          'people':clean_data(doc.people), \n",
    "                          'orgs':clean_data(doc.orgs), \n",
    "                          'exchanges':clean_data(doc.exchanges), \n",
    "                          'companies':clean_data(doc.companies), \n",
    "                          'title':clean_data(doc.title), \n",
    "                          'text':clean_text(doc.findAll('text')[0]) \n",
    "                      } )\n",
    "            data_str = data_str + ID + data\n",
    "            print('Document', data_id, 'of 8000', end='\\r')\n",
    "            data_id += 1\n",
    "    \n",
    "    with open('reuters.json', 'w') as f:\n",
    "        json.dump(data_str, f)\n",
    "                \n",
    "    return 'done'\n",
    "\n",
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_FILENAME, mode='w', encoding='utf-8') as feedsjson:\n",
    "    entry = {'name': args.name, 'url': args.url}\n",
    "    feeds.append(entry)\n",
    "    json.dump(feeds, feedsjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
