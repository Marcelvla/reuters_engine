{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Imports ######\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing document 21578 of 2157836 of 21578 812 of 21578 1140 of 21578 1280 of 215781417 of 21578 1663 of 21578of 21578 2278 of 21578 2417 of 21578 2779 of 21578 2922 of 215783407 of 21578 3660 of 21578 3779 of 21578 of 21578 4273 of 21578 4791 of 21578 of 21578 5144 of 21578 of 21578 5424 of 21578 5553 of 21578 of 21578 5802 of 21578 5932 of 21578 6140 of 21578of 21578 6534 of 21578 6660 of 21578 6799 of 21578 7218 of 215787354 of 21578 7479 of 21578of 21578 7879 of 21578 8140 of 21578 8278 of 21578 8694 of 215788817 of 21578 9273 of 21578of 21578 of 21578 9678 of 21578 10146 of 21578 10527 of 21578 10653 of 21578 10781 of 21578 of 21578 11212 of 21578 11343 of 21578 11466 of 21578 11597 of 21578 11982 of 2157812143 of 21578 12288 of 2157812423 of 2157812563 of 2157812689 of 21578 12819 of 21578 13347 of 21578of 2157813795 of 21578 13936 of 21578 14162 of 21578 of 21578 14587 of 21578of 21578 of 21578 15501 of 21578 of 2157815752 of 21578 15889 of 21578 16284 of 21578 16418 of 21578 16555 of 2157816674 of 21578 16798 of 2157817135 of 21578 of 21578of 21578of 21578 17764 of 21578 17905 of 21578 of 21578 18281 of 21578 of 21578 18676 of 21578of 2157819281 of 21578 19414 of 21578 19709 of 2157819830 of 21578of 21578 20137 of 21578 20276 of 21578of 21578 20579 of 21578 20727 of 21578 20854 of 2157820975 of 21578 21136 of 2157821411 of 21578\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removes XML tags from the data\n",
    "def clean_data(data):\n",
    "    try:\n",
    "        tags = ET.fromstring(str(data))\n",
    "        return ET.tostring(tags, method='text').decode(\"utf-8\").replace('\\'', '').replace('\\ ', '').replace('\\\"','')\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "# Finds all different places and removes the XML tags from them\n",
    "def clean_places(places):\n",
    "    placelist = []\n",
    "    for i in places:\n",
    "        tags = ET.fromstring(str(i))\n",
    "        placelist.append(ET.tostring(tags, method='text').decode(\"utf-8\"))\n",
    "        \n",
    "    return placelist\n",
    "\n",
    "# Removes title, place and the XML tags from the text\n",
    "def clean_text(text):\n",
    "    for tag in text.findAll():\n",
    "        tag.replaceWith('')\n",
    "    \n",
    "    text = text.text.replace('\\n',' ').replace('\\\"', '').replace('\\'', '').replace('\\ ','')\n",
    "    \n",
    "    return re.sub('[\\x7f]', '', text)\n",
    "\n",
    "def clean_year(data):\n",
    "    year = re.search('[0-9][0-9][0-9][0-9]', str(data)).group(0)\n",
    "    return str(year)\n",
    "\n",
    "# Creates dictionary with all documents in the Reuters database, assigns doc_ID to all documents. \n",
    "def load_data():\n",
    "    data_dict = {}\n",
    "    data_id = 0\n",
    "    \n",
    "    with open('reuters.json', 'w') as f:\n",
    "        for i in range(22):\n",
    "            if i < 10:\n",
    "                data1 = open('reuters_data/reut2-00'+ str(i) +'.sgm')\n",
    "            else:\n",
    "                data1 = open('reuters_data/reut2-0'+ str(i) +'.sgm')\n",
    "            soup = BeautifulSoup(data1,'lxml')\n",
    "            items = soup.findAll('reuters')\n",
    "\n",
    "            for doc in items:\n",
    "                ID =     {'index':{'_id':str(data_id)}}\n",
    "                data =   {    'date':clean_year(doc.date),\n",
    "                              'topic':clean_data(doc.topics), \n",
    "                              'place':clean_places(doc.places.findAll('d')), \n",
    "                              'people':clean_data(doc.people), \n",
    "                              'orgs':clean_data(doc.orgs), \n",
    "                              'exchanges':clean_data(doc.exchanges), \n",
    "                              'companies':clean_data(doc.companies), \n",
    "                              'title':clean_data(doc.title), \n",
    "                              'text':clean_text(doc.findAll('text')[0]) \n",
    "                          }\n",
    "                \n",
    "                json.dump(ID, f)\n",
    "                json.dump(data, f)\n",
    "\n",
    "                print('Indexing document', data_id + 1, 'of 21578', end='\\r')\n",
    "                data_id += 1\n",
    "        \n",
    "#         f = f.replace('\\'', '\\\"')\n",
    "    \n",
    "    return 'done'\n",
    "\n",
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt', 'w') as f:\n",
    "    for i in range(5):\n",
    "        f.write(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01234\n"
     ]
    }
   ],
   "source": [
    "with open('test.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
